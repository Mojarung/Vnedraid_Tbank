#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞ –ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç
"""

from kommersant_parser import KommersantParser

def simple_example():
    """–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç...")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = KommersantParser(delay=0.5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ 0.5 —Å–µ–∫—É–Ω–¥—ã
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
    print("\nüì∞ –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏...")
    news = parser.parse_main_page()
    
    if news:
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 –Ω–æ–≤–æ—Å—Ç–∏
        for i, article in enumerate(news[:3], 1):
            print(f"\n{i}. {article.title}")
            print(f"   üìÖ {article.datetime}")
            print(f"   üè∑Ô∏è  {article.rubric}")
            if article.author:
                print(f"   ‚úçÔ∏è  {article.author}")
            print(f"   üîó {article.url}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏")
        return

    # 2. –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–µ—Ä–≤–æ–π —Å—Ç–∞—Ç—å–∏
    print(f"\nüìñ –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏: {news[0].title}")
    full_article = parser.parse_article(news[0].url)
    
    if full_article and full_article.content:
        print("‚úÖ –¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –ø–æ–ª—É—á–µ–Ω:")
        print(f"üìù {full_article.content}")
        print(f"\nüìä –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(full_article.content)} —Å–∏–º–≤–æ–ª–æ–≤")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏")

    # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
    parser.save_to_json(news[:10], 'latest_news.json')
    parser.save_to_csv(news[:5], 'latest_news.csv')
    print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª—ã latest_news.json –∏ latest_news.csv")

def search_example():
    """–ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    print("\nüîç –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π...")
    
    parser = KommersantParser(delay=0.5)
    
    # –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É
    search_query = "—ç–∫–æ–Ω–æ–º–∏–∫–∞"
    print(f"–ò—â–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{search_query}'")
    
    results = parser.search_news(search_query, limit=5)
    
    if results:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        for i, article in enumerate(results, 1):
            print(f"{i}. {article.title}")
            print(f"   üìÖ {article.datetime}")
            print(f"   üîó {article.url}")
            print()
    else:
        print("‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

def rubric_example():
    """–ü—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π —Ä—É–±—Ä–∏–∫–∏"""
    print("\nüìÇ –ü—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π —Ä—É–±—Ä–∏–∫–∏...")
    
    parser = KommersantParser(delay=0.5)
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ —Ä—É–±—Ä–∏–∫–∏ "–û–±—â–µ—Å—Ç–≤–æ" (ID: 7)
    rubric_news = parser.get_rubric_news(7, limit=5)
    
    if rubric_news:
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(rubric_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ —Ä—É–±—Ä–∏–∫–∏ '–û–±—â–µ—Å—Ç–≤–æ':")
        for i, article in enumerate(rubric_news, 1):
            print(f"{i}. {article.title}")
            print(f"   üìÖ {article.datetime}")
            print()
    else:
        print("‚ùå –ù–æ–≤–æ—Å—Ç–∏ —Ä—É–±—Ä–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

def get_article_with_content():
    """–ü—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏ —Å –ø–æ–ª–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º"""
    print("\nüìÑ –ü—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏...")
    
    parser = KommersantParser(delay=0.5)
    
    # URL –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π)
    article_url = "https://www.kommersant.ru/doc/7794143"
    
    article = parser.parse_article(article_url)
    
    if article:
        print("‚úÖ –°—Ç–∞—Ç—å—è –ø–æ–ª—É—á–µ–Ω–∞:")
        print(f"üì∞ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {article.title}")
        print(f"üìÖ –î–∞—Ç–∞: {article.datetime}")
        print(f"üè∑Ô∏è  –†—É–±—Ä–∏–∫–∞: {article.rubric}")
        print(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ: {article.description}")
        
        if article.content:
            print(f"\nüìñ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ ({len(article.content)} —Å–∏–º–≤–æ–ª–æ–≤):")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤
            print(article.content[:300] + "..." if len(article.content) > 300 else article.content)
        else:
            print("‚ùå –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—å—é")

if __name__ == "__main__":
    print("üóûÔ∏è  –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞ –ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç")
    print("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    simple_example()
    search_example() 
    rubric_example()
    get_article_with_content()
    
    print("\nüéâ –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!")
    print("\nüí° –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç–æ–¥—ã –ø–∞—Ä—Å–µ—Ä–∞:")
    print("   - parse_main_page() - –ø–∞—Ä—Å–∏–Ω–≥ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
    print("   - parse_article(url) - –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏")
    print("   - search_news(query) - –ø–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π")
    print("   - get_rubric_news(id) - –Ω–æ–≤–æ—Å—Ç–∏ —Ä—É–±—Ä–∏–∫–∏")
    print("   - save_to_json() / save_to_csv() - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ") 